{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copia de Copia de PBL1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gC7uqwVdu7US"
      },
      "source": [
        "# **TAREA: Actividad PBL 1**\n",
        "Naive Bayes Classifier\n",
        "\n",
        "**Análisis de métodos de razonamiento e incertidumbre**\n",
        "Profesor: Daniel Otero Fadul\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "If_iONaf8iSM"
      },
      "source": [
        "Integrantes Equipo 4:\n",
        "* Álvaro López\n",
        "* Celinna Arellano\n",
        "* Lolyna de la Fuente\n",
        "* Luis Gabriel Martínez\n",
        "* María del Carmen Vargas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "do6fxm9x9B9i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9765e231-ada8-4fc6-e56b-da439f71b8fd"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7A6xi_axvUog"
      },
      "source": [
        "# **Problematización**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T31VAFmhvXtu"
      },
      "source": [
        "Los correos electrónicos categorizados como “spam” son aquellos que se mandan en grandes cantidades a millones de cuentas sin haber sido solicitados. La mayoría de estos tienen una finalidad comercial, pueden ser: ventas y publicidad, masivos o avisos de virus (también llamados hoax), enviados mediante virus y phishing. \n",
        "La mayoría de los servidores de correos electrónicos tienen un programa que puede reconocer los correos, categorizarlos como “spam” o no spam y automáticamente mandarlos a una bandeja en específico. \n",
        "Como se puede imaginar, más allá de ser un correo más a una bandeja, estos correos pueden implicar un riesgo para el usuario pues algunos como los de phishing pueden robar la información del usuario o instalar un virus que puede afectar a su equipo. \n",
        "Por esta razón, el objetivo de este escrito y proceso al que hace referencia será encontrar indicadores que permitan la categorización de los correos electrónicos de nuestra base de datos como “spam” o “ham”.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uwrmG3Xvcft"
      },
      "source": [
        "# **Enfoque**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aogndckbveI2"
      },
      "source": [
        "Teniendo en mente este escenario y aprovechando los beneficios que Python puede ofrecer para la resolución de este tipo de problemáticas, lo que se busca dentro de este proyecto es implementar un modelo clasificador estadístico que sea capaz de poder clasificar lo más cercano a lo correcto posible si un email es spam o no es spam. Y para llegar a esta parte del problema, primero hay que llevar a cabo una serie de pasos que vayan pavimentando esta trayectoría hacia la meta. A continuación se describe la estrategia de trabajo dentro de este cuaderno: \n",
        "\n",
        "1. Se importan las librerías necesarias, de manera general, se encuentran pandas, numpy, re, matplotlib, seaborn y  nltk. (Más adelante se verán las extensiones utilizadas).\n",
        "\n",
        "\n",
        "2. Se descarga el dataset de Kaggle con el que se 3. trabajará: ‘spam.csv’ y se formatea a data frame.\n",
        "\n",
        "\n",
        "3. Limpieza de los datos: primero se checan la cantidad de valores nulos por columna, en segundo se eliminan aquellas que no representen valor, en tercer lugar se renombran por fines prácticos las columnas restantes y finalmente se cambia la columna categórica a una de tipo binario que clasifique con el número 1 los correos spam y 0 los que no lo son. \n",
        "\n",
        "\n",
        "4. Visualización de los datos: Con un histograma y un pie chart se puede observar el contraste entre la cantidad de correos spam y no spam, así como sus porcentajes respectivos. Nos permiten darnos una idea más entendible y comprender la magnitud de la situación de esta base de datos. \n",
        "\n",
        "\n",
        "5. Procesamiento de texto: Es importante reducir y simplificar la base de datos para obtener un mejor desempeño, para esto, primero se imprime el diccionario de “stopwords” del lenguaje inglés y, para este caso, se agregan “u, ur, urs, urself, 2, 4, n” a este mismo. \n",
        "Después, se crea una función que convierte a minúsculas cada mensaje, así como también elimina simultáneamente los caracteres especiales y las palabras “vacías” que son las definidas anteriormente como “stop words”.  Esto último es en donde se eliminan las palabras que son poco representativas para nosotros y que a su vez son palabras muy generales, como lo son para el caso de las conjunciones, preposiciones y verbos muy comunes. \n",
        "\n",
        "\n",
        "6. Aplicación de procesamiento PLN “Stemming”, la cual es una heurística que elimina/deriva las últimas partes de una palabra hasta llegar a sufijos y prefijos comunes. Adicionalmente, también se aplicó el procesamiento “Lemmatization”, el cual toma en consideración la gramática y encuentra la raíz de las palabras.\n",
        "\n",
        "\n",
        "7. Fase de training y testing de los datos en donde separamos el 80% de estos hacía training y el 20% hacía testing de manera aleatoria para poder implementar de manera correcta el modelo clasificador.\n",
        "\n",
        "\n",
        "8. Creación de función bag of words que calcula la cantidad de palabras que se encuentran por tipo de correo, será de utilidad para calcular sus probabilidades dentro del clasificador. \n",
        "\n",
        "\n",
        "9. Creación de la función probability of words utilizando Naive Bayes para cada una de las palabras por cada tipo de correo.\n",
        "\n",
        "\n",
        "10. Haciendo uso de los datos separados en training y testing, se obtienen las probabilidades de que un correo sea o no spam, así como las probabilidades de que una palabra sea de tipo spam o ham. Adicionalmente, se agregó la columna ‘Length’ para medir el tamaño de los correos categorizados como spam o ham. \n",
        "\n",
        "\n",
        "11. Se desarrolla el clasificador probabilístico Maximum A Posteriori (MAP) dentro de una función llamada classify email. \n",
        "\n",
        "\n",
        "12. Del grupo de datos resguardados en testing, se aplica el modelo clasificador y se observan las predicciones en una nueva columna.\n",
        "\n",
        "\n",
        "13. Se evalúa el modelo con métricas tales como confusion matrix, accuracy, precision, recall y F1 score.\n",
        "\n",
        "\n",
        "14. Se razonan los pasos 12 y 13  en conjunto para llegar a una conclusión final.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EP1175rlwXD4"
      },
      "source": [
        "# **Propósitos**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UrvPqJYmwY2B"
      },
      "source": [
        "El propósito principal del reporte es la generación de un método con uso de conceptos probabilísticos para la asignación de entidades, en forma de cadenas de texto procedientes de correos electrónicos, a las categorías Spam y Ham (No Spam). Esto refiriéndose a la clasificación que se hace en clientes modernos de correo electrónico para filtrar correos no deseados con fines no confiables o comerciales que serían no deseados por los usuarios en un contexto.\n",
        "\n",
        "Además de tener como propósito principal ello, se tiene como fin secundario el poder demostrar la utilidad de la lógica del teorema de Bayes para su uso en utilidades técnicas de la vida real como, siendo el caso de este reporte la clasificación de correo no deseado.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pAJIMeJwenI"
      },
      "source": [
        "# **Información**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBuUANYIwiNF"
      },
      "source": [
        "Los clasificadores ingenuos de Bayes son un algoritmo simple de probabilidad que se basa en que todas las características del modelo son independientes. Por ejemplo, en el caso que se tiene de filtrado de spam, se está asumiendo que todas las palabras que están en el mensaje son independientes entre ellas y no se toma en cuenta el contexto. Este algoritmo lo que busca conseguir es la probabilidad de que cada mensaje sea o no spam. Esto se basa en el modelo matemático de Bayes (Maximum A Posteriori)  el cual consiste de esta forma: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9Gd5WWxwrjX"
      },
      "source": [
        "#### Maximum A Posteriori Model (MAP)\n",
        "An email is categorized as spam if\n",
        " \n",
        "$$\n",
        "\\begin{align}\n",
        "P(spam|w_1\\cap w_2\\cap\\cdots\\cap w_n) > P(not~spam|w_1\\cap w_2\\cap\\cdots\\cap w_n),\n",
        "\\end{align}\n",
        "$$\n",
        " \n",
        "which is equivalent to\n",
        " \n",
        "$$\n",
        "\\begin{align}\n",
        "P(w_1|spam)P(w_2|spam)\\cdots P(w_n|spam)P(spam) > P(w_1|not~spam)P(w_2|not~spam)\\cdots P(w_n|not~spam)P(not~spam).\n",
        "\\end{align}\n",
        "$$\n",
        " \n",
        "Notice that it is not necessary to calculate $P(w_1\\cap w_2\\cap\\cdots\\cap w_n)$. For classifying emails we will employ this method.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVX5M3a_wzfI"
      },
      "source": [
        "Para la implementación del algoritmo se hizo referencia a la guía paso a paso publicada por Towards Data Science, la cual muestra primero una breve explicación del funcionamiento del algoritmo. Después nos muestra 4 pasos simples: \n",
        "1. La limpieza de la base de datos \n",
        "\n",
        "2. La preparación de los datos \n",
        "\n",
        "3. La implementación \n",
        "\n",
        "4. Los resultados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WePPj1oUxAZC"
      },
      "source": [
        "Por otro lado, también se tomó en consideración el artículo “Laplace smoothing in Naïve Bayes algorithm” publicado por Towards Data Science, en el que se menciona el escenario en donde una palabra no forme parte del dataset contenido dentro del training set. En ese caso, no hay un “likelyhood” para esa palabra, entonces, dicho artículo da a conocer diversos acercamientos para resolverlos, entre ellos ignorar el término o encontrarse con el problema de la probabilidad de cero, generando un caos. Esto último se menciona ya que se intentó implementar la segunda opción y lo que ocasionó fue tomar dichas probabilidades como cero y asignar muchos falsos negativos que se vieron reflejados dentro de la matriz de confusión.\n",
        "\n",
        "Se tomó la iniciativa de no tomar en cuenta aquellos términos que no se encuentren dentro del training set y, desde otro punto de vista, se implementó la resolución de otro escenario en el que en esta ocasión exista la misma probabilidad de ser o no spam para el mismo correo, y para solucionarlo se compararon las longitudes del promedio de ambos tipos de correo con respecto el correo que se está tratando de clasificar, y seleccionar bajo cierta condición implementada dentro del código si se clasifica como spam o ham. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KOF5t77xDyG"
      },
      "source": [
        "# **Razonamiento**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmQSYOiKxNXk"
      },
      "source": [
        "# Razonamiento e intuición de Texto:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1W0_9CWHxRnU"
      },
      "source": [
        "Como ya se sabe los correos electrónicos están compuestos de cadenas de texto que deben ser procesadas de manera que puedan ser usadas para los métodos probabilísticos de teorema de Bayes del clasificador Naive Bayes. Primero que nada, para la ejecución del proceso de preparación de los datos, se cargan los contenidos de correos electrónicos ya anteriormente clasificados. Los contenidos que se toman en cuenta para esto son: contenido de texto del correo y clasificación en forma de “spam” y “ham”. Es decir, los datos van en forma de tabla donde en una columna se encuentran los contenidos de texto de todo un correo y su clasificación por registro.\n",
        "Por motivos de errores de carga de datos y limpieza, se tuvieron que borrar unas columnas sin datos llamadas “unnamed” y cambiar los nombres de las columnas restantes. Además de ello, también se decidió por hacer una transformación de las etiquetas de clases “spam” y “ham” a etiquetas binarias con 1 y 0 respectivamente. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_3l1q4H9Mv9",
        "outputId": "7505f523-29b6-41b8-8843-3ec2f091f3e7"
      },
      "source": [
        "# Importamos Librerías\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.stem import PorterStemmer,  WordNetLemmatizer\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbTMkssMwdyn"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DW0P-NUA95jO"
      },
      "source": [
        "Acerca de la base de datos:\n",
        "\n",
        "The SMS Spam Collection is a set of SMS tagged messages that have been collected for SMS Spam research. It contains one set of SMS messages in English of 5,574 messages, tagged acording being ham (legitimate) or spam.\n",
        "\n",
        "The files contain one message per line. Each line is composed by two columns: v1 contains the label (ham or spam) and v2 contains the raw text."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZI1BkJMCst7"
      },
      "source": [
        "# Lectura y Limpieza de Datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "cqiYid6K--GR",
        "outputId": "cc0d4d9f-a87c-4122-d5e4-d208af68dcbe"
      },
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/Classroom/spam.csv', encoding= 'latin-1')\n",
        "data.head(10)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>v1</th>\n",
              "      <th>v2</th>\n",
              "      <th>Unnamed: 2</th>\n",
              "      <th>Unnamed: 3</th>\n",
              "      <th>Unnamed: 4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>spam</td>\n",
              "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>ham</td>\n",
              "      <td>Even my brother is not like to speak with me. ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>ham</td>\n",
              "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>spam</td>\n",
              "      <td>WINNER!! As a valued network customer you have...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>spam</td>\n",
              "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     v1  ... Unnamed: 4\n",
              "0   ham  ...        NaN\n",
              "1   ham  ...        NaN\n",
              "2  spam  ...        NaN\n",
              "3   ham  ...        NaN\n",
              "4   ham  ...        NaN\n",
              "5  spam  ...        NaN\n",
              "6   ham  ...        NaN\n",
              "7   ham  ...        NaN\n",
              "8  spam  ...        NaN\n",
              "9  spam  ...        NaN\n",
              "\n",
              "[10 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rJiGVXqAQ8U",
        "outputId": "cc8079cd-0989-47d2-9f52-b2653326c3cf"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5572, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JePhhJjsAKdn",
        "outputId": "761845e4-037a-4197-e25d-99a63d77496f"
      },
      "source": [
        "#Checamos por valores nulos\n",
        "data.isnull().sum()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "v1               0\n",
              "v2               0\n",
              "Unnamed: 2    5522\n",
              "Unnamed: 3    5560\n",
              "Unnamed: 4    5566\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rqw-tH9SAEqq"
      },
      "source": [
        "Nos damos cuenta que las columnas de unnamed tienen más del 95% de sus filas con valores nulos, por lo que decidimos borrarlas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuO-rpIRACvQ"
      },
      "source": [
        "#Borramos las columnas\n",
        "data = data.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], axis=1)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "wZbH3EfIAsK7",
        "outputId": "eb5e2c39-881c-4a70-c333-70df09237e34"
      },
      "source": [
        "#Llamamos las columnas por otros nombres más convenientes\n",
        "data = data.rename(columns={'v1': 'Type', 'v2': 'Message'})\n",
        "data.head(10)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Type</th>\n",
              "      <th>Message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>spam</td>\n",
              "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>ham</td>\n",
              "      <td>Even my brother is not like to speak with me. ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>ham</td>\n",
              "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>spam</td>\n",
              "      <td>WINNER!! As a valued network customer you have...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>spam</td>\n",
              "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Type                                            Message\n",
              "0   ham  Go until jurong point, crazy.. Available only ...\n",
              "1   ham                      Ok lar... Joking wif u oni...\n",
              "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3   ham  U dun say so early hor... U c already then say...\n",
              "4   ham  Nah I don't think he goes to usf, he lives aro...\n",
              "5  spam  FreeMsg Hey there darling it's been 3 week's n...\n",
              "6   ham  Even my brother is not like to speak with me. ...\n",
              "7   ham  As per your request 'Melle Melle (Oru Minnamin...\n",
              "8  spam  WINNER!! As a valued network customer you have...\n",
              "9  spam  Had your mobile 11 months or more? U R entitle..."
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "WDGBRniyBUa3",
        "outputId": "496c021d-eeac-4d8d-c130-89e1e5086b04"
      },
      "source": [
        "'''Podemos hacer una nueva columna con variable binaria \n",
        "acerca del tipo de correo y borramos la de tipo categórica'''\n",
        "\n",
        "data['Spam'] = data['Type'].map({'ham' : 0, 'spam' : 1})\n",
        "data = data.drop(['Type'], axis = 1)\n",
        "data.head(10)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Message</th>\n",
              "      <th>Spam</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Even my brother is not like to speak with me. ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>WINNER!! As a valued network customer you have...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             Message  Spam\n",
              "0  Go until jurong point, crazy.. Available only ...     0\n",
              "1                      Ok lar... Joking wif u oni...     0\n",
              "2  Free entry in 2 a wkly comp to win FA Cup fina...     1\n",
              "3  U dun say so early hor... U c already then say...     0\n",
              "4  Nah I don't think he goes to usf, he lives aro...     0\n",
              "5  FreeMsg Hey there darling it's been 3 week's n...     1\n",
              "6  Even my brother is not like to speak with me. ...     0\n",
              "7  As per your request 'Melle Melle (Oru Minnamin...     0\n",
              "8  WINNER!! As a valued network customer you have...     1\n",
              "9  Had your mobile 11 months or more? U R entitle...     1"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PhPTHQExcoW"
      },
      "source": [
        "Finalmente, para la exploración de los datos cargados ya limpios, se visualizó la proporción de registros que son los que se muestran a continuación:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 674
        },
        "id": "JgYE4PEbZ_HM",
        "outputId": "80f6b3e2-6f4e-4e5b-e1ee-eb24ddd96ba2"
      },
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "\n",
        "x= data.Spam.value_counts()\n",
        "sns.countplot(x= \"Spam\", data = data)\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "\n",
        "count = data['Spam']\n",
        "\n",
        "ham = (count == 0).sum()\n",
        "spam = (count == 1).sum()\n",
        "\n",
        "print('Number of emails: ', len(count))\n",
        "print('Number of NO SPAM emails: ', ham)\n",
        "print('Number of SPAM emails: ', spam)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of emails:  5572\n",
            "Number of NO SPAM emails:  4825\n",
            "Number of SPAM emails:  747\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "g-9ZtSlndX-s",
        "outputId": "cec6e7e9-9cc9-4a72-fc93-634011f35744"
      },
      "source": [
        "print(f'SPAM Total: {spam}. Percentage : {round(100*spam/count.shape[0],2)}%')     \n",
        "print(f'NO SPAM Total: {ham}. Percentage : {round(100*ham/count.shape[0],2)}%')   \n",
        "\n",
        "labels = [\"Ham\",\"Spam\"]\n",
        "\n",
        "plt.pie(x.values, labels= labels, autopct= \"%1.1f%%\") # visualizing using pie\n",
        "plt.show()   "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SPAM Total: 747. Percentage : 13.41%\n",
            "NO SPAM Total: 4825. Percentage : 86.59%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwRzEtbGCzbn"
      },
      "source": [
        "# Procesamiento del Texto"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLr8enKMC5G9"
      },
      "source": [
        "Antes de aplicar el clasificador se necesita simplificar el texto lo más posible para su procesamiento. Es por eso que se creó una función para hacer esto, esta función pasa todo el texto a minúsculas, después se eliminaron los caracteres especiales, los cuales son los signos de puntuación y por último se quitaron las palabras vacías. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkAZlKZuC7ty"
      },
      "source": [
        "## Palabras vacías\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M05yQscIOT8x",
        "outputId": "f5d39c6f-76d8-47c0-e5fb-7127b0183a24"
      },
      "source": [
        "#Imprimos el diccionario de stop words\n",
        "stop_words = stopwords.words('english')\n",
        "stop_words"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i',\n",
              " 'me',\n",
              " 'my',\n",
              " 'myself',\n",
              " 'we',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'you',\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " \"you'll\",\n",
              " \"you'd\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves',\n",
              " 'he',\n",
              " 'him',\n",
              " 'his',\n",
              " 'himself',\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'her',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'they',\n",
              " 'them',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'themselves',\n",
              " 'what',\n",
              " 'which',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'this',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'these',\n",
              " 'those',\n",
              " 'am',\n",
              " 'is',\n",
              " 'are',\n",
              " 'was',\n",
              " 'were',\n",
              " 'be',\n",
              " 'been',\n",
              " 'being',\n",
              " 'have',\n",
              " 'has',\n",
              " 'had',\n",
              " 'having',\n",
              " 'do',\n",
              " 'does',\n",
              " 'did',\n",
              " 'doing',\n",
              " 'a',\n",
              " 'an',\n",
              " 'the',\n",
              " 'and',\n",
              " 'but',\n",
              " 'if',\n",
              " 'or',\n",
              " 'because',\n",
              " 'as',\n",
              " 'until',\n",
              " 'while',\n",
              " 'of',\n",
              " 'at',\n",
              " 'by',\n",
              " 'for',\n",
              " 'with',\n",
              " 'about',\n",
              " 'against',\n",
              " 'between',\n",
              " 'into',\n",
              " 'through',\n",
              " 'during',\n",
              " 'before',\n",
              " 'after',\n",
              " 'above',\n",
              " 'below',\n",
              " 'to',\n",
              " 'from',\n",
              " 'up',\n",
              " 'down',\n",
              " 'in',\n",
              " 'out',\n",
              " 'on',\n",
              " 'off',\n",
              " 'over',\n",
              " 'under',\n",
              " 'again',\n",
              " 'further',\n",
              " 'then',\n",
              " 'once',\n",
              " 'here',\n",
              " 'there',\n",
              " 'when',\n",
              " 'where',\n",
              " 'why',\n",
              " 'how',\n",
              " 'all',\n",
              " 'any',\n",
              " 'both',\n",
              " 'each',\n",
              " 'few',\n",
              " 'more',\n",
              " 'most',\n",
              " 'other',\n",
              " 'some',\n",
              " 'such',\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'only',\n",
              " 'own',\n",
              " 'same',\n",
              " 'so',\n",
              " 'than',\n",
              " 'too',\n",
              " 'very',\n",
              " 's',\n",
              " 't',\n",
              " 'can',\n",
              " 'will',\n",
              " 'just',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'now',\n",
              " 'd',\n",
              " 'll',\n",
              " 'm',\n",
              " 'o',\n",
              " 're',\n",
              " 've',\n",
              " 'y',\n",
              " 'ain',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'ma',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\"]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDVLOhlWx2sf"
      },
      "source": [
        "Las palabras vacías o ‘stopwords’ se pueden considerar artículos y/o preposiciones las cuales no agregan valor alguno a los mensajes, para esto se usó la librería nltk y se descargó el corpus de stopwords. Se utilizó el corpus de stopwords en inglés ya que toda la base está en ese idioma. Además, se optó por agregar más palabras vacías las cuales se consideran importantes ya que son frases cotidianas que no estaban incluídas como ‘2’ en vez de ‘to’ o ‘4’ en vez de ‘for’, entre otras. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c36OQpAbROlo"
      },
      "source": [
        "#Agregamos más palabras vacías\n",
        "stop_words.append('u') #you\n",
        "stop_words.append('ur') #your\n",
        "stop_words.append('urs') #yours\n",
        "stop_words.append('urself') #yourself\n",
        "stop_words.append('2') # to\n",
        "stop_words.append('4') # for\n",
        "stop_words.append('n') # and"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rS4p7W73yQgT"
      },
      "source": [
        "Se utilizó el método .lower() para pasar todo a minúsculas, después se utilizó la librería ya descargada re la cuál hace operaciones de expresiones regulares. Se utilizó el re.sub con los parámetros en default para quitar los caracteres especiales. Por último, al haber hecho una ‘tokenización’ ya que se utilizó el método .split() para separar las oraciones, la función regresa solamente las palabras que no se encuentren en el corpus de palabras vacías (el cuál se mencionó anteriormente). Entonces la función regresa palabras en minúsculas, separadas y libres de caracteres especiales. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvfNmfwzTaQ0"
      },
      "source": [
        "#Hacemos una función para limpiar el texto\n",
        "def clean_data(text):\n",
        "    text = text.lower() #Pasa a minúsculas\n",
        "    text = re.sub('[^a-zA-Z0-9_]+', ' ', text) #Quita carácteres especiales\n",
        "    return [word for word in text.split() if word not in stop_words]  #Quita las palabras vacías"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "XJqedJXLUVsx",
        "outputId": "946e97c2-1668-426d-ec23-e9a3db66797f"
      },
      "source": [
        "data['Message'] = data['Message'].apply(clean_data)\n",
        "data.head(10)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Message</th>\n",
              "      <th>Spam</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[go, jurong, point, crazy, available, bugis, g...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[ok, lar, joking, wif, oni]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[free, entry, wkly, comp, win, fa, cup, final,...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[dun, say, early, hor, c, already, say]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[nah, think, goes, usf, lives, around, though]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>[freemsg, hey, darling, 3, week, word, back, l...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>[even, brother, like, speak, treat, like, aids...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>[per, request, melle, melle, oru, minnaminungi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>[winner, valued, network, customer, selected, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>[mobile, 11, months, r, entitled, update, late...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             Message  Spam\n",
              "0  [go, jurong, point, crazy, available, bugis, g...     0\n",
              "1                        [ok, lar, joking, wif, oni]     0\n",
              "2  [free, entry, wkly, comp, win, fa, cup, final,...     1\n",
              "3            [dun, say, early, hor, c, already, say]     0\n",
              "4     [nah, think, goes, usf, lives, around, though]     0\n",
              "5  [freemsg, hey, darling, 3, week, word, back, l...     1\n",
              "6  [even, brother, like, speak, treat, like, aids...     0\n",
              "7  [per, request, melle, melle, oru, minnaminungi...     0\n",
              "8  [winner, valued, network, customer, selected, ...     1\n",
              "9  [mobile, 11, months, r, entitled, update, late...     1"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fw5Qa_OlZbrO",
        "outputId": "0b67cce9-b420-4981-d778-7ea494075c40"
      },
      "source": [
        "data['Message'].iloc[2]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['free',\n",
              " 'entry',\n",
              " 'wkly',\n",
              " 'comp',\n",
              " 'win',\n",
              " 'fa',\n",
              " 'cup',\n",
              " 'final',\n",
              " 'tkts',\n",
              " '21st',\n",
              " 'may',\n",
              " '2005',\n",
              " 'text',\n",
              " 'fa',\n",
              " '87121',\n",
              " 'receive',\n",
              " 'entry',\n",
              " 'question',\n",
              " 'std',\n",
              " 'txt',\n",
              " 'rate',\n",
              " 'c',\n",
              " 'apply',\n",
              " '08452810075over18']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPL23oewyif0"
      },
      "source": [
        "Cuando ya se tuvo esta nueva base, se terminó con la ‘stemización’ o derivación de palabras a su núcleo. Este proceso cambia todas las variantes de una palabra a su núcleo entonces por ejemplo, la palabra vehículos la cambiaría a vehículo. Para esto, se utilizó PorterStemmer() el cual es una función de ntlk.stem, entonces se usó esa función para derivar las palabras restantes de la base a su núcleo, y con eso se completa el procesamiento del texto. Por último, se decidió ‘lematizar’ el texto. Esto significa que cualquier variante del verbo raíz se cambió a su verbo raíz. Esto no afectó mucho los resultados como se esperaba, pero sí lo suficiente para que se decidiera implementar con este proceso.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbPZtcf_XOf2"
      },
      "source": [
        "Derivamos las palabras usando PorterStemmer() y WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "id": "HarwK5xrXX0M",
        "outputId": "25a3dce1-20f1-4a8f-c2f2-3d72832304ca"
      },
      "source": [
        "from nltk.corpus import wordnet\n",
        "Porter = PorterStemmer()\n",
        "Lemma = WordNetLemmatizer()\n",
        "nltk.download('wordnet')\n",
        "\n",
        "data['Message'] = data['Message'].apply(lambda x : [Porter.stem(word) for word in x])\n",
        "data['Message'] = data['Message'].apply(lambda x : [Lemma.lemmatize(word, wordnet.VERB) for word in x])\n",
        "data"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Message</th>\n",
              "      <th>Spam</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[go, jurong, point, crazi, avail, bugi, great,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[ok, lar, joke, wif, oni]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[free, entri, wkli, comp, win, fa, cup, final,...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[dun, say, earli, hor, c, alreadi, say]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[nah, think, goe, usf, live, around, though]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5567</th>\n",
              "      <td>[2nd, time, tri, contact, 750, pound, prize, c...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5568</th>\n",
              "      <td>[_, b, go, esplanad, fr, home]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5569</th>\n",
              "      <td>[piti, mood, suggest]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5570</th>\n",
              "      <td>[guy, bitch, act, like, interest, buy, someth,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5571</th>\n",
              "      <td>[rofl, true, name]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5572 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Message  Spam\n",
              "0     [go, jurong, point, crazi, avail, bugi, great,...     0\n",
              "1                             [ok, lar, joke, wif, oni]     0\n",
              "2     [free, entri, wkli, comp, win, fa, cup, final,...     1\n",
              "3               [dun, say, earli, hor, c, alreadi, say]     0\n",
              "4          [nah, think, goe, usf, live, around, though]     0\n",
              "...                                                 ...   ...\n",
              "5567  [2nd, time, tri, contact, 750, pound, prize, c...     1\n",
              "5568                     [_, b, go, esplanad, fr, home]     0\n",
              "5569                              [piti, mood, suggest]     0\n",
              "5570  [guy, bitch, act, like, interest, buy, someth,...     0\n",
              "5571                                 [rofl, true, name]     0\n",
              "\n",
              "[5572 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngIZ80ObZfnd",
        "outputId": "48db3814-91d9-4171-eeb3-8da1c05f0c76"
      },
      "source": [
        "data['Message'].iloc[2]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['free',\n",
              " 'entri',\n",
              " 'wkli',\n",
              " 'comp',\n",
              " 'win',\n",
              " 'fa',\n",
              " 'cup',\n",
              " 'final',\n",
              " 'tkt',\n",
              " '21st',\n",
              " 'may',\n",
              " '2005',\n",
              " 'text',\n",
              " 'fa',\n",
              " '87121',\n",
              " 'receiv',\n",
              " 'entri',\n",
              " 'question',\n",
              " 'std',\n",
              " 'txt',\n",
              " 'rate',\n",
              " 'c',\n",
              " 'appli',\n",
              " '08452810075over18']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdU0LDevzgk5"
      },
      "source": [
        "# Desarrollo del clasificador"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDScN0uVzlgs"
      },
      "source": [
        "Se dividen los datos en datasets de training y testing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeYq1dXV8eij",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a899b475-2277-494c-8787-41bbc08a00ff"
      },
      "source": [
        "np.random.seed(298347) \n",
        "number_of_rows = data.shape[0]\n",
        "index_train = np.random.choice(range(number_of_rows), int(0.8 * number_of_rows), replace=False)\n",
        "index_test = np.asarray(list(set(range(number_of_rows)) - set(index_train)))\n",
        "train_set = data.iloc[index_train] \n",
        "test_set = data.iloc[index_test] \n",
        "print(train_set.shape)\n",
        "print(test_set.shape)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4457, 2)\n",
            "(1115, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ydx2c2UQzvv8"
      },
      "source": [
        "Con esta función podemos calcular cuántas palabras se encuentran por tipo de correo, también cuántas veces se repiten estas palabras:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmEfQLZ29scw"
      },
      "source": [
        "def bag_of_words(corpus): \n",
        "    bag_of_words = {}\n",
        "    \n",
        "    for email in corpus:\n",
        "        for word in email:\n",
        "            if word not in bag_of_words:\n",
        "                bag_of_words[word] = 1\n",
        "            else:\n",
        "                bag_of_words[word] += 1\n",
        "    \n",
        "    return bag_of_words"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5gEej1gz2SJ"
      },
      "source": [
        "Aquí se usa Naïve Bayes para calcular la probabilidad de cada una de las palabras dependiendo de el dataset en el que se encuentren (Spam o Ham):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9fNrFez9sal"
      },
      "source": [
        "def probability_words(df): \n",
        "    \n",
        "    all_words = bag_of_words(train_set[\"Message\"])\n",
        "    baggie_of_words = bag_of_words(df[\"Message\"])\n",
        "    alpha = 1 #Este se puede cambiar para obtener diferentes resultados\n",
        "\n",
        "    number_of_words = df['Message'].apply(len).sum()\n",
        "    \n",
        "    probability_words = {}\n",
        "    \n",
        "    for word, pw in baggie_of_words.items():\n",
        "        probability_words[word] = (pw + alpha)/(number_of_words + alpha * len(all_words))\n",
        "    \n",
        "    return probability_words"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Treg8NJUQRqI"
      },
      "source": [
        "Calculamos las probabilidades de los elementos que se usan en el clasificador de Naïve Bayes, con respecto a la siguiente imagen:![nB.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Hw8XZ_TQjgC"
      },
      "source": [
        "Donde P(Spam) = p_spam y todas las probabilidades condicionales de las palabras se encuentran en el diccionario de probability_spam_words.\n",
        "\n",
        "Se hace lo mismo para los correos que no son spam, esto con el fin de usar el *Maximum A Posteriori Model* (MAP) para clasificar los correos.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OKSpPzp9sXy"
      },
      "source": [
        "p_spam = train_set[train_set['Spam'] == 1].shape[0] / train_set.shape[0]\n",
        "p_not_spam = train_set[train_set['Spam'] == 0].shape[0] / train_set.shape[0]\n",
        "probability_spam_words = probability_words(train_set[train_set['Spam'] == 1])\n",
        "probability_non_spam_words = probability_words(train_set[train_set['Spam'] == 0])"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "id": "Mhht-_YOgXn_",
        "outputId": "82f3a2e7-eb3a-4c5b-d259-ba053c894ec9"
      },
      "source": [
        "train_set[\"lenght\"] = train_set[\"Message\"].apply(len)\n",
        "average_spam_len = train_set[train_set[\"Spam\"] == 1][\"lenght\"].sum() / len(train_set[train_set[\"Spam\"] == 1])\n",
        "average_non_spam_len = train_set[train_set[\"Spam\"] == 0][\"lenght\"].sum() / len(train_set[train_set[\"Spam\"] == 0])\n",
        "train_set"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Message</th>\n",
              "      <th>Spam</th>\n",
              "      <th>lenght</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4037</th>\n",
              "      <td>[hope, scare]</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4255</th>\n",
              "      <td>[aah, cuddl, would, lush, need, lot, tea, soup...</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>320</th>\n",
              "      <td>[merri, christma, babe, love, ya, kiss]</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>416</th>\n",
              "      <td>[alright, new, goal]</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4870</th>\n",
              "      <td>[well, know, mean, text]</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1779</th>\n",
              "      <td>[loan, purpos, 500, 75, 000, homeown, tenant, ...</td>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2256</th>\n",
              "      <td>[check, head, drop, stuff]</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1384</th>\n",
              "      <td>[storm, msg, wen, lift, phne, say, hello, knw,...</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3778</th>\n",
              "      <td>[claim, 200, shop, spree, call, 08717895698, m...</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1824</th>\n",
              "      <td>[send, email, id, soon]</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4457 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Message  Spam  lenght\n",
              "4037                                      [hope, scare]     0       2\n",
              "4255  [aah, cuddl, would, lush, need, lot, tea, soup...     0      10\n",
              "320             [merri, christma, babe, love, ya, kiss]     0       6\n",
              "416                                [alright, new, goal]     0       3\n",
              "4870                           [well, know, mean, text]     0       4\n",
              "...                                                 ...   ...     ...\n",
              "1779  [loan, purpos, 500, 75, 000, homeown, tenant, ...     1      19\n",
              "2256                         [check, head, drop, stuff]     0       4\n",
              "1384  [storm, msg, wen, lift, phne, say, hello, knw,...     0      30\n",
              "3778  [claim, 200, shop, spree, call, 08717895698, m...     1       7\n",
              "1824                            [send, email, id, soon]     0       4\n",
              "\n",
              "[4457 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nzhYpkERcq2"
      },
      "source": [
        "Para la clasificación de los correos, tomamos en cuenta que puede haber muchas palabras que no se encuentren dentro de nuestra base de conocimiento, por lo que tomamos la desición de ignorarlas en el caso de que no se encuentren en alguno de los diccionarios de probabilidades. En el caso de que tuvieramos un mail que tuviera la misma probabilidad tanto para SPAM como para HAM, usamos la longitud del correo como segundo factor, se calcula la distancia de la longitud del correo a clasificar con respecto al promedio de longitud de los correos de SPAM y HAM y se selecciona el que tenga la menor distancia."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wE_FQlYP9sVw"
      },
      "source": [
        "def classify_email(email):\n",
        "    \n",
        "    likelihood_spam = 1\n",
        "    likelihood_non_spam = 1\n",
        "    \n",
        "    for word in email:\n",
        "      if word in probability_non_spam_words and word in probability_spam_words:\n",
        "        likelihood_spam *= probability_spam_words[word]\n",
        "        likelihood_non_spam *= probability_non_spam_words[word]\n",
        "    \n",
        "    likelihood_spam *= p_spam\n",
        "    likelihood_non_spam *= p_not_spam\n",
        "\n",
        "    if likelihood_spam > likelihood_non_spam:\n",
        "        return 1\n",
        "    elif likelihood_spam < likelihood_non_spam:\n",
        "        return 0\n",
        "    else:\n",
        "      print(likelihood_non_spam)\n",
        "      if abs(len(email) - average_spam_len) > abs(len(email) - average_non_spam_len):\n",
        "        return 1\n",
        "      else:\n",
        "        return 0"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8eq95JPV9sTS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60b9f13f-26b9-49d4-e12d-80dcf7400092"
      },
      "source": [
        "test_set['Prediction'] = test_set['Message'].apply(lambda x : classify_email(x))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Alnid0q60DLy"
      },
      "source": [
        "# Predicción del modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CI99RX-v9sAf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "9151dc3a-70bf-47b5-f96a-79fb6f4cc0c9"
      },
      "source": [
        "test_set"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Message</th>\n",
              "      <th>Spam</th>\n",
              "      <th>Prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[go, jurong, point, crazi, avail, bugi, great,...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4099</th>\n",
              "      <td>[home, lei]</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2052</th>\n",
              "      <td>[call, 09094100151, use, min, call, cast, 10p,...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4103</th>\n",
              "      <td>[hav, frnd, name, ashwini, colleg]</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>[urgent, 1, week, free, membership, 100, 000, ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2027</th>\n",
              "      <td>[get, new, job, bar, airport, satsgettin, 47pe...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2034</th>\n",
              "      <td>[avatar, suppos, subtoitl]</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4082</th>\n",
              "      <td>[good, afternoon, love, good, see, word, ym, g...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4085</th>\n",
              "      <td>[lemm, know]</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2044</th>\n",
              "      <td>[send, pic, like]</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1115 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Message  Spam  Prediction\n",
              "0     [go, jurong, point, crazi, avail, bugi, great,...     0           0\n",
              "4099                                        [home, lei]     0           0\n",
              "2052  [call, 09094100151, use, min, call, cast, 10p,...     1           1\n",
              "4103                 [hav, frnd, name, ashwini, colleg]     0           0\n",
              "12    [urgent, 1, week, free, membership, 100, 000, ...     1           1\n",
              "...                                                 ...   ...         ...\n",
              "2027  [get, new, job, bar, airport, satsgettin, 47pe...     0           0\n",
              "2034                         [avatar, suppos, subtoitl]     0           0\n",
              "4082  [good, afternoon, love, good, see, word, ym, g...     0           0\n",
              "4085                                       [lemm, know]     0           0\n",
              "2044                                  [send, pic, like]     0           0\n",
              "\n",
              "[1115 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKZfW_Cl0JrI"
      },
      "source": [
        "# **Conclusión**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGnghw7o0Tgc"
      },
      "source": [
        "Para medir el desempeño de nuestro algoritmo se creó una matriz de confusión. Esta consiste en una tabla que compara los resultados obtenidos en una muestra de los datos contra los valores verdaderos. Tenemos las siguientes categorías: \n",
        "* Verdaderos Positivos: los valores que el programa marcó como positivos y son positivos (en este caso que son marcados como spam)\n",
        "* Verdaderos Negativos:  los que son marcados como ham y efectivamente no son spam\n",
        "* Falsos Positivos: los que son marcados como positivos (spam) pero realmente no lo son. \n",
        "* Falsos Negativos: los que son marcados como ham pero en realidad sí son spam. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0TSFsBe0duo"
      },
      "source": [
        "Con esta función hacemos la evaluación del modelo. Se hace una tabla de confusión y una tabla de métricas:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iSyW7tR-nt1"
      },
      "source": [
        "def performance_metrics(df):\n",
        "    positives = [len(test_set[(test_set[\"Prediction\"] == 1) & (test_set[\"Spam\"] == 1)]),\n",
        "                 len(test_set[(test_set[\"Prediction\"] == 1) & (test_set[\"Spam\"] == 0)])]\n",
        "    negatives = [len(test_set[(test_set[\"Prediction\"] == 0) & (test_set[\"Spam\"] == 1)]),\n",
        "                 len(test_set[(test_set[\"Prediction\"] == 0) & (test_set[\"Spam\"] == 0)])]\n",
        "    conf_mat = pd.DataFrame({\"Predicted positives\" : positives,\n",
        "                             \"Predicted negatives\" : negatives},\n",
        "                           index = [\"Actual positives\", \"Actual negatives\"])\n",
        "    \n",
        "    accuracy = (positives[0] + negatives[1])/len(df)\n",
        "    precision = positives[0]/sum(positives)\n",
        "    recall = positives[0]/(positives[0] + negatives[0])\n",
        "    f1 = 2 * (precision * recall)/(precision + recall)\n",
        "    \n",
        "    metrics = pd.DataFrame({\"Metrics\" : [accuracy, precision, recall, f1]}, \n",
        "                          index = [\"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"])\n",
        "    return [conf_mat, metrics]"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kT2jeQs9-nj9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "26645aa3-4501-4f41-a40b-6ffec8df32fc"
      },
      "source": [
        "confusion_matrix, metrics = performance_metrics(test_set)\n",
        "confusion_matrix"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predicted positives</th>\n",
              "      <th>Predicted negatives</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Actual positives</th>\n",
              "      <td>144</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Actual negatives</th>\n",
              "      <td>19</td>\n",
              "      <td>933</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  Predicted positives  Predicted negatives\n",
              "Actual positives                  144                   19\n",
              "Actual negatives                   19                  933"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdgqNRId0i5o"
      },
      "source": [
        "Como se puede observar en la matriz de confusión tenemos predicted positives y predicted negatives en la parte superior, mientras que en la lateral tenemos actual positives y actual negatives, por lo que el cuadrante [1,1] nos dirá el valor de verdaderos positivos. En este caso se tienen 144 verdaderos positivos. Después, en el cuadrante [1,2] se tienen los que el programa predijo como negativos que en realidad eran positivos (falsos negativos), para esta métrica se tienen 19 casos. Por otro lado, en el cuadrante [2,1] se tienen los falsos positivos los cuales son el número de correos que fueron categorizados como spam cuando realmente no lo eran, el número total de estos casos es de 19. Finalmente, en el cuadrante [2,2] se tienen los verdaderos negativos, que son los correos que no son spam y que el clasificador marcó como no spam, en este caso tenemos 933. \n",
        "\n",
        "Al ver estos valores se puede inferir que el desempeño del programa es bueno pues “errores” tuvo solo 38, sin embargo, para tener una mejor imagen de qué tan bueno es el programa se tienen que sacar más métricas que ayuden a visualizarlo. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKJFPpCl0mOu"
      },
      "source": [
        "Las siguientes métricas también cuantifican el comportamiento del modelo, pero de una forma distinta. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4faVXlV6-nhb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "193b5c40-dbdc-4c47-fe92-49008bc0dc6c"
      },
      "source": [
        "metrics"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Metrics</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Accuracy</th>\n",
              "      <td>0.965919</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Precision</th>\n",
              "      <td>0.883436</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Recall</th>\n",
              "      <td>0.883436</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>F1 Score</th>\n",
              "      <td>0.883436</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Metrics\n",
              "Accuracy   0.965919\n",
              "Precision  0.883436\n",
              "Recall     0.883436\n",
              "F1 Score   0.883436"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7d4XYaZ40nJ4"
      },
      "source": [
        "La métrica **Accuracy** mide el número de clasificaciones correctas sobre el total del número de casos de prueba. Tal vez esta métrica no sea un buen punto de partida para evaluar el modelo ya que se “influencia” mucho, es decir, puede inclinarse hacia un bias. Eso puede suceder dentro de datos desbalanceados. Esta métrica dio 0.96, da “buen resultado” pero es necesario el revisar las siguientes métricas para llegar a una conclusión final.\n",
        "\n",
        "La métrica ***Precision*** es la que responde a la siguiente cuestión: cuando un valor positivo es predecido como verdadero o falso (en este caso spam o no spam), ¿qué tan frecuente es esa predicción correcta? El clasificador dio un resultado de 0.883436 aproximadamente, por lo que se podría considerar como bueno, dentro de lo que cabe. \n",
        "\n",
        "La métrica ***Recall***, también conocida como la sensibilidad, responde a la siguiente pregunta: Cuando el valor es positivo, ¿qué tan frecuente es la predicción correcta? ¿Qué tan sensible es el clasificador en detectar instancias positivas? Dentro de este clasificador el resultado fue 0.883436, lo cual también resulta ser bueno ya que influye mucho el haber obtenido un valor bajo dentro de los falsos positivos. \n",
        "\n",
        "Por último, ***F1 Score***, es una combinación entre Recall y Precision, es práctico para la comparación del rendimiento directamente y el balance entre estas dos métricas mencionadas, el cuál dio un valor de 0.883436.\n",
        "\n",
        "Una observación importante es que las métricas Precision, Recall y F1Score dieron exactamente el mismo resultado. Esto tiene sentido ya que los valores para los falsos positivos y falsos negativos son el mismo valor de 19, y dichos cálculos se realizan con estas condiciones predecidas. En conclusión, el clasificador implementado funciona y da buenos resultados, sin embargo, no se descarta la idea de que puede ser mejorado.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vex-R9sWOhMn"
      },
      "source": [
        "##Fuentes:\n",
        "- Horbonos, P. (2020, 31 enero). How to build and apply Naive Bayes classification for spam filtering. Towards Data Science. https://towardsdatascience.com/how-to-build-and-apply-naive-bayes-classification-for-spam-filtering-2b8d3308501\n",
        "\n",
        "- Jayaswal, V. (2020, 22 noviembre). Laplace smoothing in Naïve Bayes algorithm. Towards Data Science. Towards Data Science. https://towardsdatascience.com/laplace-smoothing-in-na%C3%AFve-bayes-algorithm-9c237a8bdece"
      ]
    }
  ]
}